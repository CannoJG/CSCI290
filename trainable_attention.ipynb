{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3880b57c",
   "metadata": {},
   "source": [
    "## Attention With Trainable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78633be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2fdbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7105,  0.6528, -0.2157, -0.2809, -0.8114, -0.3414,  0.2661, -2.0810],\n",
       "        [-2.2361, -0.5939,  0.2585, -0.7939,  0.7677, -0.9950, -0.8082,  1.3309],\n",
       "        [ 1.0520,  1.1614,  0.9447, -1.6995,  0.2667,  1.2736, -0.9009, -0.8989],\n",
       "        [-0.2590,  0.7640, -0.6376, -0.0187, -0.5093, -0.4221, -1.6806, -0.7567]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb047287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensions\n",
    "d_in = 8\n",
    "d_out = 6\n",
    "# Create Weight Matricies query,key,value with random entries\n",
    "W_q = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_k = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_v = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbaa6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1566,  0.8889,  1.4499,  0.2406,  1.2576,  1.5981])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose an input vector (we're using 2) and transform it into our query vector using using W_q\n",
    "query = inputs[2] @ W_q\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c209fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0291, -1.6117, -0.8521, -1.3628, -0.3105, -1.4809],\n",
      "        [-1.9449, -1.9627, -3.0443, -0.8610, -2.1701, -2.1570],\n",
      "        [ 2.2391,  1.0842,  0.7962,  0.9442,  1.9731,  0.0738],\n",
      "        [-2.1021, -1.8340, -1.7885, -1.9287, -1.5862, -2.4269]])\n",
      "tensor([[-1.4337e-01, -1.0559e+00, -3.0322e-01, -5.6192e-01, -2.0256e+00,\n",
      "         -1.5472e+00],\n",
      "        [-2.2791e+00, -1.7411e+00, -3.3669e+00, -1.4210e+00, -7.3777e-01,\n",
      "         -1.5988e+00],\n",
      "        [ 1.3259e+00,  3.6476e-01,  9.8852e-01,  1.6805e-01, -8.3493e-01,\n",
      "          9.2886e-04],\n",
      "        [-1.7319e+00, -2.5013e+00, -2.5635e+00, -1.0488e+00, -2.8878e+00,\n",
      "         -1.5334e+00]])\n"
     ]
    }
   ],
   "source": [
    "#Calculate attention scores using the keys generates by W_k\n",
    "\n",
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "print(keys)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2cbbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -5.5919, -12.2375,   4.5941, -10.2315])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = query @ keys.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e3eb9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7692e-05, 4.8987e-08, 9.9996e-01, 3.6416e-07])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the scores to get the weights\n",
    "attention_weights = torch.softmax(attention_scores, dim= -1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bf510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure you did it right\n",
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b4dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3259e+00,  3.6471e-01,  9.8847e-01,  1.6802e-01, -8.3498e-01,\n",
       "         8.6987e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the context vector\n",
    "context_vector = attention_weights @ values\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74bc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
