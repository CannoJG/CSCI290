{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3880b57c",
   "metadata": {},
   "source": [
    "## Attention With Trainable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78633be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2fdbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1235,  0.3848,  0.2176, -0.1915,  0.3218, -1.1199,  0.4628,  1.0018],\n",
       "        [-0.2260,  1.5758,  0.1162, -1.9782, -0.3457, -1.1353,  1.3096,  0.4596],\n",
       "        [-0.3055,  0.7803, -2.1933,  0.9615,  0.2858,  1.4231,  0.7304,  0.7601],\n",
       "        [ 0.1555, -2.5241,  1.0640,  0.1207,  0.7441, -1.2528,  1.6269, -1.0157]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb047287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensions\n",
    "d_in = 8\n",
    "d_out = 6\n",
    "# Create Weight Matricies query, key, value with random entries\n",
    "W_q = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_k = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_v = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbaa6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6538, 1.5932, 1.6082, 0.8148, 0.4994, 1.3328])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose an input vector (we're using 2) and transform it into our query vector using using W_q\n",
    "query = inputs[2] @ W_q\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c209fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1261,  0.3428,  0.6490,  1.6041,  0.8039,  0.6276],\n",
      "        [-0.3990, -1.6304, -0.3453, -0.6979,  0.7171,  0.0516],\n",
      "        [ 2.2449,  2.9626,  0.7028,  0.0294,  2.8479,  1.7154],\n",
      "        [-0.2247, -2.1196,  0.9183, -0.3535, -1.9207,  0.3464]])\n",
      "tensor([[ 1.6006,  0.6530,  1.9231,  0.7862,  1.2701,  1.1857],\n",
      "        [-0.2345, -0.8941, -0.1930, -1.8626,  0.3781, -0.9824],\n",
      "        [ 1.4429,  0.8960,  2.4966,  0.7620,  0.5672,  0.9624],\n",
      "        [-0.0681, -0.5490, -2.6490,  1.0066, -0.5846,  0.9395]])\n"
     ]
    }
   ],
   "source": [
    "#Calculate keys and values matrices\n",
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "print(keys)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2cbbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.9973, -3.9544, 13.2953, -3.0572])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = query @ keys.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3eb9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8267e-02, 8.3025e-04, 9.4971e-01, 1.1975e-03])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the scores to get the weights\n",
    "# denominator is just because that's what the researchers figured out worked best for training \n",
    "attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim= -1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b59bf510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure you did it right\n",
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013b4dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4473, 0.8811, 2.4605, 0.7613, 0.5996, 0.9715])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the context vector\n",
    "context_vector = attention_weights @ values\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851252b0",
   "metadata": {},
   "source": [
    "## Making the Simple Attention Class Using Parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e31084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e74bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simple attention class v1\n",
    "class SimpleAttention(nn.Module):\n",
    "    #Constructor, initialize those matrix dimensions\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        #Create weight matrices\n",
    "        self.W_q = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "        self.W_k = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "        self.W_v = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "    #   x = embedding vectors (inputs)\n",
    "    def forward(self,x):\n",
    "        #Make the queries, keys and values\n",
    "        queries = x @ self.W_q\n",
    "        keys = x @ self.W_k\n",
    "        values = x @ self.W_v\n",
    "        #Compute scores, then normalize into weights\n",
    "        scores = queries @ keys.T\n",
    "        weights = torch.softmax(scores / keys.shape[-1]**0.5, dim= -1)\n",
    "        #Compute context vector using weights and values\n",
    "        context = weights @ values\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f7212fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the class example\n",
    "#instatiate an instance\n",
    "simple = SimpleAttention(d_in = 8, d_out = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3314d6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1909, 0.7732, 0.1293, 0.9050, 0.7625, 0.0677],\n",
       "        [0.5439, 0.8092, 0.6802, 0.0667, 0.9650, 0.8042],\n",
       "        [0.5610, 0.0248, 0.1272, 0.1991, 0.9177, 0.0663],\n",
       "        [0.9340, 0.2450, 0.0773, 0.9778, 0.0867, 0.3319],\n",
       "        [0.8942, 0.1181, 0.7229, 0.6745, 0.9474, 0.2715],\n",
       "        [0.3403, 0.5913, 0.8111, 0.3381, 0.6692, 0.8602],\n",
       "        [0.7867, 0.0910, 0.5758, 0.8477, 0.7767, 0.7543],\n",
       "        [0.2919, 0.8024, 0.7835, 0.4280, 0.0323, 0.3201]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It has attributes!\n",
    "simple.W_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bddbb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4453,  0.9395,  1.9048,  1.3181,  0.5674,  1.5561],\n",
       "        [-0.6997,  0.5977, -0.4032, -0.6267,  0.0862, -1.3821],\n",
       "        [ 1.4512,  0.6566,  2.5537,  1.9153,  0.5605,  1.8776],\n",
       "        [-0.7949,  0.6097, -0.6143, -0.9525,  0.0121, -1.5324]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class returns the context vector\n",
    "context_vectors = simple(inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fcedc",
   "metadata": {},
   "source": [
    "## Making the Simple Attention Class Again using nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "849378f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simple attention class v2\n",
    "#Using nn.Linear to be more efficient\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "    #Constructor, initialize those matrix dimensions\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        #Create weight matrices\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    #   x = embedding vectors (inputs)\n",
    "    def forward(self,x):\n",
    "        #Make the queries, keys and values\n",
    "        #Still just muktiplying the matrices\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v (x)\n",
    "        #Compute scores, then normalize into weights\n",
    "        scores = queries @ keys.T\n",
    "        weights = torch.softmax(scores / keys.shape[-1]**0.5, dim= -1)\n",
    "        #Compute context vector using weights and values\n",
    "        context = weights @ values\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66b88466",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = SimpleAttention(d_in = 8, d_out = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc53ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320, 0.2654, 0.2398, 0.2627],\n",
       "        [0.1815, 0.1899, 0.2234, 0.4052],\n",
       "        [0.2624, 0.2063, 0.3141, 0.2171],\n",
       "        [0.2308, 0.4676, 0.1540, 0.1475]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple(inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa90eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the problem here is that each context vector uses information from ALL of the embedding vectors\n",
    "#In practice, we should only use information about preceeding vectors\n",
    "# To do so, implement causal attention AKA masked attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf49ae0",
   "metadata": {},
   "source": [
    "### Simple Masked Attention (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320, 0.2654, 0.2398, 0.2627],\n",
       "        [0.1815, 0.1899, 0.2234, 0.4052],\n",
       "        [0.2624, 0.2063, 0.3141, 0.2171],\n",
       "        [0.2308, 0.4676, 0.1540, 0.1475]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hack to get some weights\n",
    "#weights = simple(inputs)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c1c06c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that these are already normalized\n",
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0fa77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tril returns the lower triangular parts of the matrix (and the diagonal), turns the rest to zero\n",
    "simple_mask = torch.tril(torch.ones(weights.shape[0], weights.shape[0]))\n",
    "simple_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43678b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1815, 0.1899, 0.0000, 0.0000],\n",
       "        [0.2624, 0.2063, 0.3141, 0.0000],\n",
       "        [0.2308, 0.4676, 0.1540, 0.1475]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * is a cell by cell product\n",
    "masked_weights = weights*simple_mask\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efbd431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2320, 0.3715, 0.7829, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no longer normalized...\n",
    "masked_weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f16722fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320],\n",
       "        [0.3715],\n",
       "        [0.7829],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to normalize masked weights\n",
    "row_sums = masked_weights.sum(dim=-1, keepdim=True)\n",
    "row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db15db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing by row sums normalizes\n",
    "masked_weights = masked_weights / row_sums\n",
    "masked_weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180b3bf",
   "metadata": {},
   "source": [
    "### More Efficient Masking Method (1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a44b47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking method 2\n",
    "# triu() returns the upper triangular part of the matrix, puts zeros on the diagonal\n",
    "mask = torch.triu(torch.ones(weights.shape[0], weights.shape[0]), diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0925012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "035acb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320, 0.2654, 0.2398, 0.2627],\n",
       "        [0.1815, 0.1899, 0.2234, 0.4052],\n",
       "        [0.2624, 0.2063, 0.3141, 0.2171],\n",
       "        [0.2308, 0.4676, 0.1540, 0.1475]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb57a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2320,   -inf,   -inf,   -inf],\n",
       "        [0.1815, 0.1899,   -inf,   -inf],\n",
       "        [0.2624, 0.2063, 0.3141,   -inf],\n",
       "        [0.2308, 0.4676, 0.1540, 0.1475]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need a matrix of true/false to fill in, fills the true spots with the given value (-inf)\n",
    "weights = weights.masked_fill(mask.bool(), -torch.inf, )\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68c54035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4979, 0.5021, 0.0000, 0.0000],\n",
       "        [0.3335, 0.3153, 0.3512, 0.0000],\n",
       "        [0.2431, 0.3081, 0.2251, 0.2237]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights = torch.softmax(weights, dim=-1)\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834b832",
   "metadata": {},
   "source": [
    "### Dropout Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropout helps us avoid overfitting during training \n",
    "# (don't want to overfit to training set bc then model cannot generalize)\n",
    "# Randomly and uniformly ignoring certain data points\n",
    "# we must set a dropout rate\n",
    "dropout = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9cdd322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.9958, 1.0042, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.7024, 0.0000],\n",
       "        [0.4862, 0.6161, 0.0000, 0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It removes around half of the data points ...\n",
    "dropout(masked_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b13733",
   "metadata": {},
   "source": [
    "## Causal Attenion Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e668c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to be able to give our LLM batches of input\n",
    "# For example:\n",
    "# Concatenates two tensors\n",
    "batches = torch.stack((inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42b59aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1235,  0.3848,  0.2176, -0.1915,  0.3218, -1.1199,  0.4628,\n",
       "           1.0018],\n",
       "         [-0.2260,  1.5758,  0.1162, -1.9782, -0.3457, -1.1353,  1.3096,\n",
       "           0.4596],\n",
       "         [-0.3055,  0.7803, -2.1933,  0.9615,  0.2858,  1.4231,  0.7304,\n",
       "           0.7601],\n",
       "         [ 0.1555, -2.5241,  1.0640,  0.1207,  0.7441, -1.2528,  1.6269,\n",
       "          -1.0157]],\n",
       "\n",
       "        [[ 1.1235,  0.3848,  0.2176, -0.1915,  0.3218, -1.1199,  0.4628,\n",
       "           1.0018],\n",
       "         [-0.2260,  1.5758,  0.1162, -1.9782, -0.3457, -1.1353,  1.3096,\n",
       "           0.4596],\n",
       "         [-0.3055,  0.7803, -2.1933,  0.9615,  0.2858,  1.4231,  0.7304,\n",
       "           0.7601],\n",
       "         [ 0.1555, -2.5241,  1.0640,  0.1207,  0.7441, -1.2528,  1.6269,\n",
       "          -1.0157]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02db0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this class needs to handle batches of input\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        #Create weight matrices\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=False)\n",
    "        # include dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #Use the following to manage memory efficiently:\n",
    "        self.register_buffer(\n",
    "            'mask', \n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "            )\n",
    "\n",
    "    #   x = embedding vectors (inputs)\n",
    "    def forward(self,x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        #Make the queries, keys and values\n",
    "        #Still just muktiplying the matrices\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v (x)\n",
    "        #Compute scores, then normalize into weights (doing dot products of queries and keys)\n",
    "        scores = queries @ keys.transpose(1,2)\n",
    "        #masking process: turns into trues/falses then converts some into -inf which is normalized to 0 in next step\n",
    "        scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        #Normalize, -inf turns into zeros\n",
    "        weights = torch.softmax(scores / keys.shape[-1]**0.5, dim= -1)\n",
    "        weights = self.dropout(weights)\n",
    "        #Compute context vector using weights and values\n",
    "        context = weights @ values\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a915b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a causal attention mechanism\n",
    "causal = CausalAttention(d_in=8, d_out=4, context_length= 4, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "747b63e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5388, -0.1939, -0.3264,  0.0441],\n",
       "         [-0.1614, -0.1862, -0.0703,  0.0295],\n",
       "         [ 0.1411,  0.0746, -0.0504, -0.3851],\n",
       "         [-0.0500,  0.2988, -0.6009, -0.0190]],\n",
       "\n",
       "        [[-0.5388, -0.1939, -0.3264,  0.0441],\n",
       "         [-0.1614, -0.1862, -0.0703,  0.0295],\n",
       "         [ 0.1411,  0.0746, -0.0504, -0.3851],\n",
       "         [-0.0500,  0.2988, -0.6009, -0.0190]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360252c5",
   "metadata": {},
   "source": [
    "### an example of how to transpose batches correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50be6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_q = nn.Linear(d_in, d_out, bias=False)\n",
    "W_k = nn.Linear(d_in, d_out, bias=False)\n",
    "W_v = nn.Linear(d_in, d_out, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d91ad457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2543, -0.1610,  0.0497, -0.9070, -0.5010,  0.3876],\n",
       "         [-0.8582, -0.3220,  0.1259, -0.9665,  0.5995,  0.5388],\n",
       "         [-1.2267, -0.5747,  0.4660,  0.6398, -0.0497,  0.2588],\n",
       "         [ 0.5372,  0.8420, -0.9136,  0.1309,  0.2768, -0.7435]],\n",
       "\n",
       "        [[ 0.2543, -0.1610,  0.0497, -0.9070, -0.5010,  0.3876],\n",
       "         [-0.8582, -0.3220,  0.1259, -0.9665,  0.5995,  0.5388],\n",
       "         [-1.2267, -0.5747,  0.4660,  0.6398, -0.0497,  0.2588],\n",
       "         [ 0.5372,  0.8420, -0.9136,  0.1309,  0.2768, -0.7435]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = W_q(batches)\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8999fa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0905,  0.1475, -0.8634, -0.1281,  0.2515, -0.3039],\n",
       "         [-0.1949,  0.4223, -0.0847, -1.2047,  1.0438, -0.7071],\n",
       "         [ 0.1571,  0.9005, -1.0104, -0.1815, -0.5400,  0.4482],\n",
       "         [ 0.0291, -0.0851, -0.3023,  0.4536, -0.6966, -0.2584]],\n",
       "\n",
       "        [[-0.0905,  0.1475, -0.8634, -0.1281,  0.2515, -0.3039],\n",
       "         [-0.1949,  0.4223, -0.0847, -1.2047,  1.0438, -0.7071],\n",
       "         [ 0.1571,  0.9005, -1.0104, -0.1815, -0.5400,  0.4482],\n",
       "         [ 0.0291, -0.0851, -0.3023,  0.4536, -0.6966, -0.2584]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = W_k(batches)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71b6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0905, -0.1949,  0.1571,  0.0291],\n",
       "         [ 0.1475,  0.4223,  0.9005, -0.0851],\n",
       "         [-0.8634, -0.0847, -1.0104, -0.3023],\n",
       "         [-0.1281, -1.2047, -0.1815,  0.4536],\n",
       "         [ 0.2515,  1.0438, -0.5400, -0.6966],\n",
       "         [-0.3039, -0.7071,  0.4482, -0.2584]],\n",
       "\n",
       "        [[-0.0905, -0.1949,  0.1571,  0.0291],\n",
       "         [ 0.1475,  0.4223,  0.9005, -0.0851],\n",
       "         [-0.8634, -0.0847, -1.0104, -0.3023],\n",
       "         [-0.1281, -1.2047, -0.1815,  0.4536],\n",
       "         [ 0.2515,  1.0438, -0.5400, -0.6966],\n",
       "         [-0.3039, -0.7071,  0.4482, -0.2584]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This transposes without mixing up the batches\n",
    "keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780bb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
