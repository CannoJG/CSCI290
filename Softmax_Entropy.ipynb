{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e302e2ee",
   "metadata": {},
   "source": [
    "# Calculating Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7984a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c82b41",
   "metadata": {},
   "source": [
    "### Input Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667728cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9, -2.1, -0.3, 0.4, -0.8], [0.3, 2.5, -0.5, 0.0, -1.1], [-0.6, 0.2, 1.4, -0.9, -0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of logits in a vocab of length 5\n",
    "inputs = []\n",
    "inputs.append([1.9, -2.1, -0.3, 0.4, -0.8])\n",
    "inputs.append([0.3, 2.5, -0.5, 0.0, -1.1])\n",
    "inputs.append([-0.6, 0.2, 1.4, -0.9, -0.2])\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9887b30",
   "metadata": {},
   "source": [
    "### Indicate Position of Correct Token in Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98edeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the positions of the logits of the correct next word\n",
    "# This list indicates that for the 1st batch the 2nd token is the correct next word, \n",
    "# the 2nd batch- the 1st token, the 3rd batch- the 3rd token)\n",
    "\n",
    "correct = [1,0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a216b1",
   "metadata": {},
   "source": [
    "## Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b68c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exps = [math.exp(x[i]) for i in range(len(x))]\n",
    "    total = sum(exps)\n",
    "    return [exps[i]/total for i in range(len(exps))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74723b35",
   "metadata": {},
   "source": [
    "## Here are the Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5fd34bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7044960025395535, 0.01290329438107122, 0.07806038213502133, 0.15719430587057923, 0.04734601507377475] 1.0\n",
      "[0.08724665367176511, 0.7874022271681335, 0.0392024485170282, 0.06463391073355108, 0.021514759909522087] 0.9999999999999999\n",
      "[0.07783773045595785, 0.17323105491069887, 0.5751473569525154, 0.05766360897828585, 0.11612024870254202] 1.0\n"
     ]
    }
   ],
   "source": [
    "# convert logits into probabilities using softmax\n",
    "probs = []\n",
    "for i in range(len(inputs)):\n",
    "    probs.append(softmax(inputs[i]))\n",
    "    print(probs[i], sum(probs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a71cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01290329438107122, 0.08724665367176511, 0.5751473569525154]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the probabilities at the CORRECT positions (2nd, 1st, 3rd respectively)\n",
    "targets = [probs[0][correct[0]],probs[1][correct[1]], probs[2][correct[2]]]\n",
    "print (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612d652",
   "metadata": {},
   "source": [
    "## Compute Cross Entropy/Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "13bc9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentr(p,t):\n",
    "    return -math.log(p[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d656aa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3502726218404035, 2.4390160719673135, 0.5531289980561963]\n",
      "2.4474725639546375\n"
     ]
    }
   ],
   "source": [
    "loglist= []\n",
    "for i in range(len(targets)):\n",
    "    loglist.append(crossentr(targets,i))\n",
    "crossentropy = sum(loglist)/len(loglist)\n",
    "\n",
    "print(loglist)\n",
    "print(crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12762bbd",
   "metadata": {},
   "source": [
    "## Verification that My Code Actualy Works Correctly Using Torch Built In Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f23328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Calculated Loss: 2.4474725639546375\n",
      "Correct Loss From Torch: 2.44747257232666\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as F\n",
    "\n",
    "logits = torch.tensor([[1.9, -2.1, -0.3, 0.4, -0.8], [0.3, 2.5, -0.5, 0.0, -1.1], [-0.6, 0.2, 1.4, -0.9, -0.2]])\n",
    "target_labels = torch.tensor([1, 0, 2])\n",
    "\n",
    "# Compute the loss using the built-in torch function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits, target_labels)\n",
    "\n",
    "print('My Calculated Loss:',crossentropy )\n",
    "print('Correct Loss From Torch:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f537a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
