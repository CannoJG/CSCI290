{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b645fdbb",
   "metadata": {},
   "source": [
    "## Coding Assignment Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e5744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212, 318, 616, 3290, 11595, 417]\n"
     ]
    }
   ],
   "source": [
    "#tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
    "#enc_text = tokenizer.encode(raw_text)\n",
    "#print (enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792b9108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.7065,  2.0925, -0.8239, -0.0056],\n",
      "        [ 0.9185, -0.3213,  0.6459,  0.2323],\n",
      "        [-0.8132, -1.6316, -0.0272,  1.9398],\n",
      "        [ 0.3847,  0.6870, -0.7064,  1.5958],\n",
      "        [-2.1451, -1.4466,  0.0126,  0.2701],\n",
      "        [-2.4113,  0.2163,  0.9638, -0.1118],\n",
      "        [ 1.5943,  0.1567, -0.6557, -1.8912],\n",
      "        [ 0.7813, -0.6892, -2.3990,  0.1003]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8\n",
    "output_dim = 4\n",
    "inputs = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(inputs.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24ab8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7065,  2.0925, -0.8239, -0.0056],\n",
       "        [ 0.9185, -0.3213,  0.6459,  0.2323],\n",
       "        [-0.8132, -1.6316, -0.0272,  1.9398],\n",
       "        [ 0.3847,  0.6870, -0.7064,  1.5958],\n",
       "        [-2.1451, -1.4466,  0.0126,  0.2701],\n",
       "        [-2.4113,  0.2163,  0.9638, -0.1118],\n",
       "        [ 1.5943,  0.1567, -0.6557, -1.8912],\n",
       "        [ 0.7813, -0.6892, -2.3990,  0.1003]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This gets rid of the grad = True thing\n",
    "inputs = inputs.weight.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66755e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5568, -1.8548, -2.8281,  1.7388, -1.5233,  1.3628, -0.2476, -0.0182],\n",
       "        [-1.8548,  1.4180,  0.2104,  0.0470, -1.4345, -1.6877,  0.5512, -0.5871],\n",
       "        [-2.8281,  0.2104,  7.0871,  1.6811,  4.6282,  1.3649, -5.2030,  0.7491],\n",
       "        [ 1.7388,  0.0470,  1.6811,  3.6654, -1.3968, -1.6382, -1.8338,  1.6818],\n",
       "        [-1.5233, -1.4345,  4.6282, -1.3968,  6.7670,  4.8415, -4.1657, -0.6819],\n",
       "        [ 1.3628, -1.6877,  1.3649, -1.6382,  4.8415,  6.8026, -4.2311, -4.3563],\n",
       "        [-0.2476,  0.5512, -5.2030, -1.8338, -4.1657, -4.2311,  6.5730,  2.5209],\n",
       "        [-0.0182, -0.5871,  0.7491,  1.6818, -0.6819, -4.3563,  2.5209,  6.8509]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all attention scores for all input vectors via matrix multiplication (@) easier than by for loops\n",
    "attention_scores = inputs @ inputs.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5e83de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5644e-01, 5.7793e-04, 2.1835e-04, 2.1016e-02, 8.0504e-04, 1.4429e-02,\n",
       "         2.8832e-03, 3.6266e-03],\n",
       "        [1.6860e-02, 4.4482e-01, 1.3296e-01, 1.1292e-01, 2.5666e-02, 1.9925e-02,\n",
       "         1.8696e-01, 5.9893e-02],\n",
       "        [4.5081e-05, 9.4101e-04, 9.1229e-01, 4.0955e-03, 7.8027e-02, 2.9854e-03,\n",
       "         4.1937e-06, 1.6128e-03],\n",
       "        [9.9557e-02, 1.8336e-02, 9.3967e-02, 6.8358e-01, 4.3281e-03, 3.3998e-03,\n",
       "         2.7958e-03, 9.4039e-02],\n",
       "        [1.9837e-04, 2.1679e-04, 9.3123e-02, 2.2513e-04, 7.9050e-01, 1.1526e-01,\n",
       "         1.4122e-05, 4.6014e-04],\n",
       "        [3.7747e-03, 1.7866e-04, 3.7825e-03, 1.8774e-04, 1.2236e-01, 8.6969e-01,\n",
       "         1.4044e-05, 1.2391e-05],\n",
       "        [1.0685e-03, 2.3749e-03, 7.5272e-06, 2.1871e-04, 2.1238e-05, 1.9895e-05,\n",
       "         9.7926e-01, 1.7025e-02],\n",
       "        [1.0159e-03, 5.7508e-04, 2.1881e-03, 5.5606e-03, 5.2308e-04, 1.3268e-05,\n",
       "         1.2869e-02, 9.7726e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize them \n",
    "attention_weights = torch.softmax(attention_scores, dim = -1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a381cfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c61c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6964,  2.0152, -0.7992,  0.0222],\n",
       "        [ 0.5737, -0.2918, -0.0567,  0.1985],\n",
       "        [-0.9127, -1.5992, -0.0272,  1.7974],\n",
       "        [ 0.1935,  0.4488, -0.7797,  1.2818],\n",
       "        [-2.0488, -1.2703,  0.1172,  0.3817],\n",
       "        [-2.3651,  0.0129,  0.8364, -0.0565],\n",
       "        [ 1.5759,  0.1433, -0.6825, -1.8494],\n",
       "        [ 0.7830, -0.6701, -2.3573,  0.0871]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ inputs\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07ed68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
